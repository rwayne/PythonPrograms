{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets -- training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading the training and validation datasets\n",
    "#df_train = pd.read_csv(\"C:\\HuiLi_work\\SAS_work\\Data\\cs_accepts_train.csv\")\n",
    "#df_validation = pd.read_csv(\"C:\\HuiLi_work\\SAS_work\\Data\\cs_accepts_validation.csv\")\n",
    "df_train = pd.read_csv(\"C:\\demodata\\cs_accepts_train.csv\")\n",
    "df_validation = pd.read_csv(\"c:\\demodata\\cs_accepts_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver the categorical to numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importing LabelEncoder and initializing it\n",
    "le=LabelEncoder()\n",
    "#Iterating over all the common columns in train and test\n",
    "for col in df_train.columns.values:\n",
    "    #Encoding only categorical variables\n",
    "    if df_train[col].dtypes=='object':\n",
    "        #Using whole data to form an exhausitve list of levels\n",
    "        df=df_validation[col].append(df_train[col])\n",
    "        le.fit(df.values)\n",
    "        df_train[col]=le.transform(df_train[col])\n",
    "        df_validation[col]=le.transform(df_validation[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List variable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numList = [\"Nchildren\",\"Nhousehold\",\"Age\",\"TimeAddress\",\"TimeJob\",\"tel\",\"NumMyLoan\",\"NumFinLoan\",\"NumLoans\",\n",
    "          \"Income\",\"EC_Card\",\"IncLevel\",\"bureau\",\"region\",\"regionLarge\",\"cash\"]  ## with missing\n",
    "                                                      ## without missing\n",
    "#numList = [\"Nchildren\",\"Nhousehold\",\"Age\",\"tel\",\"NumMyLoan\",\n",
    "#                \"NumFinLoan\",\"NumLoans\",\"Income\",\"EC_Card\",\"IncLevel\",\"bureau\",\"region\",\"regionLarge\", \n",
    "#                \"cash\"] ## without missing    \n",
    "catList =  [\"title\",\"status\",\"resid\",\"nat\", \"prof\",\"car\",\"card\",\"saving\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the dataframes to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat        =  numList+catList;\n",
    "labels      = ['target']\n",
    "trainFeat   = df_train.as_matrix(feat)              # training features\n",
    "trainLabels = df_train.as_matrix(labels)            # training target\n",
    "validationFeat   = df_validation.as_matrix(feat)    # validation features\n",
    "validationLabels = df_validation.as_matrix(labels)  # validation target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the missing data and impute the missing value with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking the number of missing for each coloumn\n",
    "for i in range(0,len(feat)):\n",
    "    aa =np.count_nonzero(~np.isnan(trainFeat[:,i]))\n",
    "    print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imputing the missing data\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "trainFeat_im = imp.fit_transform(trainFeat)\n",
    "valiFeat_im = imp.fit_transform(validationFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(feat)):\n",
    "    aa =np.count_nonzero(~np.isnan(valiFeat_im[:,i]))\n",
    "    print aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the randome forest objuect which will include all the parameters for the fit\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "# Fit the training features to the training labels and build the random forest model \n",
    "rf.fit(trainFeat_im, trainLabels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the scores of validation datasets\n",
    "testPreds =rf.predict(valiFeat_im)\n",
    "#print testPreds\n",
    "metrics.confusion_matrix(validationLabels,testPreds)\n",
    "metrics.accuracy_score(validationLabels,testPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute the roc and auc for validation\n",
    "validationPreds_proba =rf.predict_proba(valiFeat_im)[:,1]\n",
    "fpr, tpr, tresh = metrics.roc_curve(validationLabels,validationPreds_proba)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the scores of train datasets\n",
    "trainPreds =rf.predict(trainFeat_im)\n",
    "#print testPreds\n",
    "metrics.confusion_matrix(trainLabels,trainPreds)\n",
    "metrics.accuracy_score(trainLabels,trainPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute the roc and auc for training\n",
    "trainPreds_proba =rf.predict_proba(trainFeat_im)[:,1]\n",
    "fpr_train, tpr_train, tresh_train = metrics.roc_curve(trainLabels,trainPreds_proba)\n",
    "auc_train = metrics.auc(fpr_train,tpr_train)\n",
    "print auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
